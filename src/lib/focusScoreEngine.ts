// AI ëª¨ë¸ ê¸°ë°˜ ì§‘ì¤‘ë„ ì ìˆ˜ ê³„ì‚° ì—”ì§„

export interface FocusFeatures {
  // ì‹œê°ì  ì§€í‘œ
  visual?: {
    eyeStatus: 'OPEN' | 'CLOSED' | 'PARTIAL'
    earValue: number // 0.1 ~ 0.5 (ëˆˆì´ ì—´ë ¤ìˆì„ìˆ˜ë¡ ë†’ìŒ)
    headPose: {
      pitch: number // -20Â° ~ +20Â°
      yaw: number   // -30Â° ~ +30Â°
      roll: number  // -10Â° ~ +10Â°
    }
    gazeDirection: 'FORWARD' | 'LEFT' | 'RIGHT' | 'UP' | 'DOWN'
  }
  
  // ì²­ê°ì  ì§€í‘œ
  audio?: {
    isSpeaking: boolean
    speechContent: string
    isStudyRelated: boolean
    confidence: number // 0.0 ~ 1.0
    audioLevel: number // 0 ~ 100
    speechStartTime?: number // ë°œí™” ì‹œì‘ ì‹œê°„ (íƒ€ì„ìŠ¤íƒ¬í”„)
    speechEndTime?: number // ë°œí™” ì¢…ë£Œ ì‹œê°„ (íƒ€ì„ìŠ¤íƒ¬í”„)
  }
  
  // í–‰ë™ ì§€í‘œ
  behavior?: {
    mouseActivity: boolean
    keyboardActivity: boolean
    tabSwitches: number
    idleTime: number // ì´ˆ ë‹¨ìœ„
  }
  
  // ì‹œê°„ ì§€í‘œ
  time?: {
    sessionDuration: number // ë¶„ ë‹¨ìœ„
    lastBreakTime: number // ë¶„ ë‹¨ìœ„
    consecutiveFocusTime: number // ë¶„ ë‹¨ìœ„
  }

  // íƒ€ì„ìŠ¤íƒ¬í”„ (ë³´ì • ë¡œì§ì„ ìœ„í•œ ì¶”ê°€)
  timestamp?: number
}

// ì§‘ì¤‘ ìƒíƒœ íƒ€ì… ì •ì˜
export type FocusStatus = 'focused' | 'normal' | 'distracted'

// ì§‘ì¤‘ ìƒíƒœ íŒë‹¨ ê²°ê³¼
export interface FocusStatusResult {
  status: FocusStatus
  confidence: number
  score: number
  factors: {
    eyeFactor: number
    headPoseFactor: number
    audioFactor: number
    behaviorFactor: number
  }
  isCorrected?: boolean // ë³´ì • ì—¬ë¶€
  correctionReason?: string // ë³´ì • ì´ìœ 
}

// ì§‘ì¤‘ë„ íˆìŠ¤í† ë¦¬ ì €ì¥ì†Œ
class FocusScoreHistory {
  private static instance: FocusScoreHistory
  private history: Array<{
    timestamp: number
    score: number
    confidence: number
    features: FocusFeatures
    isSpeechRelated: boolean
  }> = []
  private maxHistorySize = 10 // ìµœëŒ€ 10ê°œì˜ ì´ì „ ê¸°ë¡ ì €ì¥

  static getInstance(): FocusScoreHistory {
    if (!FocusScoreHistory.instance) {
      FocusScoreHistory.instance = new FocusScoreHistory()
    }
    return FocusScoreHistory.instance
  }

  addRecord(timestamp: number, score: number, confidence: number, features: FocusFeatures, isSpeechRelated: boolean = false) {
    this.history.push({
      timestamp,
      score,
      confidence,
      features,
      isSpeechRelated
    })

    // ìµœëŒ€ í¬ê¸° ì´ˆê³¼ ì‹œ ì˜¤ë˜ëœ ê¸°ë¡ ì œê±°
    if (this.history.length > this.maxHistorySize) {
      this.history.shift()
    }
  }

  // ìµœê·¼ ë¹„ë°œí™” ì‹œì ì˜ ì§‘ì¤‘ë„ ì •ë³´ ì¡°íšŒ
  getLastNonSpeechScore(currentTimestamp: number, timeWindowMs: number = 10000): {
    score: number
    confidence: number
    timeDiff: number
  } | null {
    // í˜„ì¬ ì‹œê°„ì—ì„œ timeWindowMs ì´ë‚´ì˜ ê¸°ë¡ ì¤‘ ë°œí™”ì™€ ê´€ë ¨ì—†ëŠ” ë§ˆì§€ë§‰ ê¸°ë¡ ì°¾ê¸°
    const timeThreshold = currentTimestamp - timeWindowMs
    
    for (let i = this.history.length - 1; i >= 0; i--) {
      const record = this.history[i]
      
      if (record.timestamp >= timeThreshold && 
          record.timestamp < currentTimestamp && 
          !record.isSpeechRelated) {
        return {
          score: record.score,
          confidence: record.confidence,
          timeDiff: currentTimestamp - record.timestamp
        }
      }
    }

    return null
  }

  // ìµœê·¼ í‰ê·  ì§‘ì¤‘ë„ ì¡°íšŒ (ë°œí™” ì œì™¸)
  getRecentAverageScore(currentTimestamp: number, timeWindowMs: number = 30000): {
    averageScore: number
    averageConfidence: number
    sampleCount: number
  } | null {
    const timeThreshold = currentTimestamp - timeWindowMs
    const relevantRecords = this.history.filter(record => 
      record.timestamp >= timeThreshold && 
      record.timestamp < currentTimestamp && 
      !record.isSpeechRelated
    )

    if (relevantRecords.length === 0) {
      return null
    }

    const totalScore = relevantRecords.reduce((sum, record) => sum + record.score, 0)
    const totalConfidence = relevantRecords.reduce((sum, record) => sum + record.confidence, 0)

    return {
      averageScore: totalScore / relevantRecords.length,
      averageConfidence: totalConfidence / relevantRecords.length,
      sampleCount: relevantRecords.length
    }
  }
}

// ì§‘ì¤‘ ìƒíƒœ íŒë‹¨ í•¨ìˆ˜
export function determineFocusStatus(features: FocusFeatures): FocusStatusResult {
  let totalScore = 0
  let totalConfidence = 0
  let factorCount = 0
  
  const factors = {
    eyeFactor: 0,
    headPoseFactor: 0,
    audioFactor: 0,
    behaviorFactor: 0
  }

  let isCorrected = false
  let correctionReason = ''

  // ë°œí™” ì‹œì  ì§‘ì¤‘ë„ ë³´ì • ë¡œì§
  const history = FocusScoreHistory.getInstance()
  const currentTimestamp = features.timestamp || Date.now()
  
  // í•™ìŠµ ê´€ë ¨ ë°œí™” ì¤‘ì¸ì§€ í™•ì¸
  const isStudyRelatedSpeech = features.audio?.isSpeaking && 
                              features.audio?.isStudyRelated && 
                              features.audio?.confidence && features.audio.confidence > 0.7

  if (isStudyRelatedSpeech) {
    console.log('ğŸ¯ í•™ìŠµ ê´€ë ¨ ë°œí™” ê°ì§€ - ì§‘ì¤‘ë„ ë³´ì • ë¡œì§ ì ìš©')
    
    // ìµœê·¼ ë¹„ë°œí™” ì‹œì ì˜ ì§‘ì¤‘ë„ ì •ë³´ ì¡°íšŒ
    const lastNonSpeechScore = history.getLastNonSpeechScore(currentTimestamp, 15000) // 15ì´ˆ ì´ë‚´
    const recentAverage = history.getRecentAverageScore(currentTimestamp, 30000) // 30ì´ˆ ì´ë‚´
    
    if (lastNonSpeechScore && lastNonSpeechScore.timeDiff < 10000) { // 10ì´ˆ ì´ë‚´
      // ìµœê·¼ ë¹„ë°œí™” ì‹œì ì˜ ì§‘ì¤‘ë„ë¥¼ í˜„ì¬ ì‹œì ì— ì ìš©
      totalScore = lastNonSpeechScore.score
      totalConfidence = Math.min(1.0, lastNonSpeechScore.confidence + 0.1) // ì‹ ë¢°ë„ ì•½ê°„ ì¦ê°€
      isCorrected = true
      correctionReason = `í•™ìŠµ ê´€ë ¨ ë°œí™” ì¤‘ - ${(lastNonSpeechScore.timeDiff / 1000).toFixed(1)}ì´ˆ ì „ ì§‘ì¤‘ë„(${lastNonSpeechScore.score}) ì ìš©`
      
      console.log(`âœ… ì§‘ì¤‘ë„ ë³´ì • ì ìš©: ${correctionReason}`)
    } else if (recentAverage && recentAverage.sampleCount >= 2) {
      // ìµœê·¼ í‰ê·  ì§‘ì¤‘ë„ ì ìš©
      totalScore = recentAverage.averageScore
      totalConfidence = Math.min(1.0, recentAverage.averageConfidence + 0.05)
      isCorrected = true
      correctionReason = `í•™ìŠµ ê´€ë ¨ ë°œí™” ì¤‘ - ìµœê·¼ í‰ê·  ì§‘ì¤‘ë„(${recentAverage.averageScore.toFixed(1)}) ì ìš©`
      
      console.log(`âœ… ì§‘ì¤‘ë„ ë³´ì • ì ìš©: ${correctionReason}`)
    } else {
      // ë³´ì • ì •ë³´ê°€ ì—†ìœ¼ë©´ ë†’ì€ ê¸°ë³¸ê°’ ì ìš©
      totalScore = 75 // í•™ìŠµ ê´€ë ¨ ë°œí™” ì‹œ ê¸°ë³¸ì ìœ¼ë¡œ ì§‘ì¤‘ ìƒíƒœë¡œ ê°„ì£¼
      totalConfidence = 0.8
      isCorrected = true
      correctionReason = 'í•™ìŠµ ê´€ë ¨ ë°œí™” ì¤‘ - ê¸°ë³¸ ì§‘ì¤‘ ìƒíƒœë¡œ ì„¤ì •'
      
      console.log(`âœ… ì§‘ì¤‘ë„ ë³´ì • ì ìš©: ${correctionReason}`)
    }
    
    // ë³´ì •ëœ ê²½ìš° ê¸°ë³¸ ê³„ì‚°ì€ ê±´ë„ˆë›°ê³  ë°”ë¡œ ê²°ê³¼ ë°˜í™˜
    factorCount = 1
  } else {
    // ê¸°ì¡´ ì§‘ì¤‘ë„ ê³„ì‚° ë¡œì§ (ë³´ì •ì´ ì ìš©ë˜ì§€ ì•Šì€ ê²½ìš°)
    
    // 1. ì‹œê°ì  ì§€í‘œ ë¶„ì„ (ëˆˆ ìƒíƒœ, ë¨¸ë¦¬ ìì„¸)
    if (features.visual) {
      const { eyeStatus, earValue, headPose } = features.visual
      
      // ëˆˆ ìƒíƒœ ë¶„ì„
      let eyeScore = 0
      let eyeConfidence = 0.5
      
      if (eyeStatus === 'OPEN') {
        eyeScore = 80 + (earValue * 40) // 80-100ì 
        eyeConfidence = 0.8
      } else if (eyeStatus === 'PARTIAL') {
        eyeScore = 40 + (earValue * 40) // 40-80ì 
        eyeConfidence = 0.6
      } else if (eyeStatus === 'CLOSED') {
        eyeScore = 0 + (earValue * 20) // 0-20ì 
        eyeConfidence = 0.9
      }
      
      factors.eyeFactor = eyeScore
      
      // ë¨¸ë¦¬ ìì„¸ ë¶„ì„
      let headPoseScore = 100
      let headPoseConfidence = 0.7
      
      // ë¨¸ë¦¬ê°€ ë„ˆë¬´ ë§ì´ ê¸°ìš¸ì–´ì§€ë©´ ì ìˆ˜ ê°ì 
      const pitchDeviation = Math.abs(headPose.pitch)
      const yawDeviation = Math.abs(headPose.yaw)
      const rollDeviation = Math.abs(headPose.roll)
      
      if (pitchDeviation > 15) headPoseScore -= 30
      if (yawDeviation > 25) headPoseScore -= 30
      if (rollDeviation > 8) headPoseScore -= 20
      
      factors.headPoseFactor = Math.max(0, headPoseScore)
      
      // ì‹œê°ì  ì§€í‘œ ì¢…í•© ì ìˆ˜
      const visualScore = (eyeScore + headPoseScore) / 2
      const visualConfidence = (eyeConfidence + headPoseConfidence) / 2
      
      totalScore += visualScore
      totalConfidence += visualConfidence
      factorCount++
    }

    // 2. ì²­ê°ì  ì§€í‘œ ë¶„ì„
    if (features.audio) {
      const { isStudyRelated, confidence, audioLevel } = features.audio
      
      let audioScore = 50 // ê¸°ë³¸ê°’
      let audioConfidence = confidence || 0.5
      
      if (isStudyRelated) {
        audioScore = 80 + (confidence * 20) // 80-100ì 
      } else {
        audioScore = 20 + (confidence * 30) // 20-50ì 
      }
      
      // ì¡°ìš©í•œ í™˜ê²½ì´ë©´ ì ìˆ˜ ê°€ì‚°
      if (audioLevel < 30) {
        audioScore += 10
      }
      
      factors.audioFactor = Math.min(100, audioScore)
      totalScore += audioScore
      totalConfidence += audioConfidence
      factorCount++
    }

    // 3. í–‰ë™ ì§€í‘œ ë¶„ì„
    if (features.behavior) {
      const { mouseActivity, keyboardActivity, tabSwitches, idleTime } = features.behavior
      
      let behaviorScore = 50 // ê¸°ë³¸ê°’
      let behaviorConfidence = 0.6
      
      // ë§ˆìš°ìŠ¤/í‚¤ë³´ë“œ í™œë™ì´ ìˆìœ¼ë©´ ì ìˆ˜ ê°€ì‚°
      if (mouseActivity || keyboardActivity) {
        behaviorScore += 20
      }
      
      // íƒ­ ì „í™˜ì´ ì ìœ¼ë©´ ì ìˆ˜ ê°€ì‚°
      if (tabSwitches < 3) {
        behaviorScore += 15
      } else {
        behaviorScore -= (tabSwitches - 2) * 5
      }
      
      // ìœ íœ´ ì‹œê°„ì´ ì ìœ¼ë©´ ì ìˆ˜ ê°€ì‚°
      if (idleTime < 60) { // 1ë¶„ ë¯¸ë§Œ
        behaviorScore += 15
      } else {
        behaviorScore -= Math.min(30, idleTime / 60 * 5)
      }
      
      factors.behaviorFactor = Math.max(0, Math.min(100, behaviorScore))
      totalScore += behaviorScore
      totalConfidence += behaviorConfidence
      factorCount++
    }

    // 4. ì‹œê°„ ì§€í‘œ ë¶„ì„
    if (features.time) {
      const { sessionDuration, consecutiveFocusTime } = features.time
      
      let timeScore = 50 // ê¸°ë³¸ê°’
      let timeConfidence = 0.7
      
      // ì—°ì† ì§‘ì¤‘ ì‹œê°„ì´ ê¸¸ë©´ ì ìˆ˜ ê°€ì‚°
      if (consecutiveFocusTime > 30) { // 30ë¶„ ì´ìƒ
        timeScore += 20
      } else if (consecutiveFocusTime > 15) { // 15ë¶„ ì´ìƒ
        timeScore += 10
      }
      
      totalScore += timeScore
      totalConfidence += timeConfidence
      factorCount++
    }
  }

  // ìµœì¢… ì ìˆ˜ ê³„ì‚°
  const finalScore = factorCount > 0 ? Math.round(totalScore / factorCount) : 50
  const finalConfidence = factorCount > 0 ? totalConfidence / factorCount : 0.5

  // ì§‘ì¤‘ ìƒíƒœ íŒë‹¨
  let status: FocusStatus = 'normal'
  if (finalScore >= 75) {
    status = 'focused'
  } else if (finalScore <= 35) {
    status = 'distracted'
  }

  // íˆìŠ¤í† ë¦¬ì— ê¸°ë¡ ì¶”ê°€ (ë°œí™” ê´€ë ¨ ì—¬ë¶€ í¬í•¨)
  const isSpeechRelated = features.audio?.isSpeaking || false
  history.addRecord(currentTimestamp, finalScore, finalConfidence, features, isSpeechRelated)

  const result: FocusStatusResult = {
    status,
    confidence: finalConfidence,
    score: finalScore,
    factors
  }

  if (isCorrected) {
    result.isCorrected = true
    result.correctionReason = correctionReason
  }

  return result
}

export interface FocusScoreResult {
  score: number // 0-100
  confidence: number // 0.0-1.0
  breakdown: {
    visual: number
    audio: number
    behavior: number
    time: number
  }
  analysis: {
    primaryFactor: string
    secondaryFactor: string
    recommendations: string[]
  }
}

export class FocusScoreEngine {
  private static readonly WEIGHTS = {
    visual: 0.35,    // ì‹œê°ì  ì§€í‘œ (35%)
    audio: 0.30,     // ì²­ê°ì  ì§€í‘œ (30%)
    behavior: 0.25,  // í–‰ë™ ì§€í‘œ (25%)
    time: 0.10       // ì‹œê°„ ì§€í‘œ (10%)
  }

  /**
   * AI ëª¨ë¸ ê¸°ë°˜ ì§‘ì¤‘ë„ ì ìˆ˜ ê³„ì‚° (ë°œí™” ì‹œì  ë³´ì • í¬í•¨)
   */
  static calculateFocusScore(features: FocusFeatures): FocusScoreResult {
    // ë°œí™” ì‹œì  ë³´ì • ë¡œì§ ë¨¼ì € í™•ì¸
    const focusStatus = determineFocusStatus(features)
    
    // ë³´ì •ëœ ê²½ìš° ë³´ì •ëœ ì ìˆ˜ ì‚¬ìš©
    if (focusStatus.isCorrected) {
      return {
        score: focusStatus.score,
        confidence: focusStatus.confidence,
        breakdown: {
          visual: focusStatus.factors.eyeFactor + focusStatus.factors.headPoseFactor,
          audio: focusStatus.factors.audioFactor,
          behavior: focusStatus.factors.behaviorFactor,
          time: 50 // ê¸°ë³¸ê°’
        },
        analysis: {
          primaryFactor: 'ë°œí™” ë³´ì •',
          secondaryFactor: focusStatus.correctionReason || 'í•™ìŠµ ê´€ë ¨ ë°œí™”',
          recommendations: [
            'í•™ìŠµ ê´€ë ¨ ë°œí™”ë¡œ ì¸í•œ ì§‘ì¤‘ë„ ë³´ì •ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.',
            'ê³„ì†í•´ì„œ í•™ìŠµì— ì§‘ì¤‘í•˜ì„¸ìš”!'
          ]
        }
      }
    }

    // ë³´ì •ë˜ì§€ ì•Šì€ ê²½ìš° ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
    const scores = {
      visual: this.calculateVisualScore(features.visual),
      audio: this.calculateAudioScore(features.audio),
      behavior: this.calculateBehaviorScore(features.behavior),
      time: this.calculateTimeScore(features.time)
    }

    // ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… ì ìˆ˜ ê³„ì‚°
    const finalScore = Math.round(
      scores.visual * this.WEIGHTS.visual +
      scores.audio * this.WEIGHTS.audio +
      scores.behavior * this.WEIGHTS.behavior +
      scores.time * this.WEIGHTS.time
    )

    // ì‹ ë¢°ë„ ê³„ì‚°
    const confidence = this.calculateConfidence(features)

    // ë¶„ì„ ê²°ê³¼ ìƒì„±
    const analysis = this.generateAnalysis(scores, features)

    return {
      score: Math.max(0, Math.min(100, finalScore)),
      confidence,
      breakdown: scores,
      analysis
    }
  }

  /**
   * ì‹œê°ì  ì§‘ì¤‘ë„ ì ìˆ˜ ê³„ì‚° (0-100)
   */
  private static calculateVisualScore(visual?: FocusFeatures['visual']): number {
    if (!visual) return 50 // ê¸°ë³¸ê°’

    let score = 50

    // ëˆˆ ìƒíƒœ ê¸°ë°˜ ì ìˆ˜ (0-40ì )
    switch (visual.eyeStatus) {
      case 'OPEN':
        score += 40
        break
      case 'PARTIAL':
        score += 20
        break
      case 'CLOSED':
        score += 0
        break
    }

    // EAR ê°’ ê¸°ë°˜ ì ìˆ˜ (0-20ì )
    if (visual.earValue >= 0.3) {
      score += 20 // ëˆˆì´ ì˜ ì—´ë ¤ìˆìŒ
    } else if (visual.earValue >= 0.2) {
      score += 10 // ëˆˆì´ ë¶€ë¶„ì ìœ¼ë¡œ ì—´ë ¤ìˆìŒ
    }

    // ë¨¸ë¦¬ ìì„¸ ê¸°ë°˜ ì ìˆ˜ (0-20ì )
    const headPoseScore = this.calculateHeadPoseScore(visual.headPose)
    score += headPoseScore

    // ì‹œì„  ë°©í–¥ ê¸°ë°˜ ì ìˆ˜ (0-20ì )
    const gazeScore = this.calculateGazeScore(visual.gazeDirection)
    score += gazeScore

    return Math.max(0, Math.min(100, score))
  }

  /**
   * ë¨¸ë¦¬ ìì„¸ ì ìˆ˜ ê³„ì‚°
   */
  private static calculateHeadPoseScore(headPose: NonNullable<FocusFeatures['visual']>['headPose']): number {
    let score = 20

    // ê°ë„ê°€ í´ìˆ˜ë¡ ì ìˆ˜ ê°ì†Œ
    const pitchDeviation = Math.abs(headPose.pitch)
    const yawDeviation = Math.abs(headPose.yaw)
    const rollDeviation = Math.abs(headPose.roll)

    if (pitchDeviation > 15) score -= 5
    if (yawDeviation > 20) score -= 5
    if (rollDeviation > 8) score -= 5

    return Math.max(0, score)
  }

  /**
   * ì‹œì„  ë°©í–¥ ì ìˆ˜ ê³„ì‚°
   */
  private static calculateGazeScore(gazeDirection: string): number {
    switch (gazeDirection) {
      case 'FORWARD':
        return 20 // ì •ë©´ ì‘ì‹œ
      case 'UP':
      case 'DOWN':
        return 15 // ìœ„ì•„ë˜ë¡œ ë³´ëŠ” ê²ƒì€ í•™ìŠµ í™œë™ì¼ ìˆ˜ ìˆìŒ
      case 'LEFT':
      case 'RIGHT':
        return 10 // ì¢Œìš°ë¡œ ë³´ëŠ” ê²ƒì€ ë°©í•´ ìš”ì†Œì¼ ê°€ëŠ¥ì„±
      default:
        return 10
    }
  }

  /**
   * ì²­ê°ì  ì§‘ì¤‘ë„ ì ìˆ˜ ê³„ì‚° (0-100)
   */
  private static calculateAudioScore(audio?: FocusFeatures['audio']): number {
    if (!audio) return 50 // ê¸°ë³¸ê°’

    let score = 50

    // ë°œí™” ì—¬ë¶€ ê¸°ë°˜ ì ìˆ˜
    if (audio.isSpeaking) {
      if (audio.isStudyRelated) {
        score += 30 // í•™ìŠµ ê´€ë ¨ ë°œí™”
      } else {
        score -= 20 // í•™ìŠµê³¼ ë¬´ê´€í•œ ë°œí™”
      }
    } else {
      score += 10 // ì¡°ìš©í•¨ (ì§‘ì¤‘ ìƒíƒœì¼ ê°€ëŠ¥ì„±)
    }

    // ì‹ ë¢°ë„ ê¸°ë°˜ ì ìˆ˜ ì¡°ì •
    const confidenceAdjustment = (audio.confidence - 0.5) * 20
    score += confidenceAdjustment

    // ì˜¤ë””ì˜¤ ë ˆë²¨ ê¸°ë°˜ ì ìˆ˜ (ë„ˆë¬´ í¬ê±°ë‚˜ ì‘ìœ¼ë©´ ê°ì )
    if (audio.audioLevel > 80) {
      score -= 15 // ë„ˆë¬´ ì‹œë„ëŸ¬ì›€
    } else if (audio.audioLevel < 10) {
      score += 5 // ì ë‹¹í•œ ì¡°ìš©í•¨
    }

    return Math.max(0, Math.min(100, score))
  }

  /**
   * í–‰ë™ ê¸°ë°˜ ì§‘ì¤‘ë„ ì ìˆ˜ ê³„ì‚° (0-100)
   */
  private static calculateBehaviorScore(behavior?: FocusFeatures['behavior']): number {
    if (!behavior) return 50 // ê¸°ë³¸ê°’

    let score = 50

    // ë§ˆìš°ìŠ¤/í‚¤ë³´ë“œ í™œë™ ê¸°ë°˜ ì ìˆ˜
    if (behavior.mouseActivity || behavior.keyboardActivity) {
      score += 25 // í™œë™ì  (ì§‘ì¤‘ ìƒíƒœì¼ ê°€ëŠ¥ì„±)
    } else {
      score -= 15 // ë¹„í™œë™ì  (ì§‘ì¤‘í•˜ì§€ ì•Šì„ ê°€ëŠ¥ì„±)
    }

    // íƒ­ ì „í™˜ ê¸°ë°˜ ì ìˆ˜
    if (behavior.tabSwitches === 0) {
      score += 20 // íƒ­ ì „í™˜ ì—†ìŒ (ì§‘ì¤‘ ìƒíƒœ)
    } else if (behavior.tabSwitches <= 2) {
      score += 10 // ì ì€ íƒ­ ì „í™˜
    } else {
      score -= 20 // ê³¼ë„í•œ íƒ­ ì „í™˜
    }

    // ìœ íœ´ ì‹œê°„ ê¸°ë°˜ ì ìˆ˜
    if (behavior.idleTime < 30) {
      score += 20 // 30ì´ˆ ë¯¸ë§Œ ìœ íœ´
    } else if (behavior.idleTime < 120) {
      score += 10 // 2ë¶„ ë¯¸ë§Œ ìœ íœ´
    } else {
      score -= 20 // 2ë¶„ ì´ìƒ ìœ íœ´
    }

    return Math.max(0, Math.min(100, score))
  }

  /**
   * ì‹œê°„ ê¸°ë°˜ ì§‘ì¤‘ë„ ì ìˆ˜ ê³„ì‚° (0-100)
   */
  private static calculateTimeScore(time?: FocusFeatures['time']): number {
    if (!time) return 50 // ê¸°ë³¸ê°’

    let score = 50

    // ì„¸ì…˜ ì§€ì†ì‹œê°„ ê¸°ë°˜ ì ìˆ˜
    if (time.sessionDuration >= 60) {
      score += 20 // 1ì‹œê°„ ì´ìƒ ì§€ì†
    } else if (time.sessionDuration >= 30) {
      score += 15 // 30ë¶„ ì´ìƒ ì§€ì†
    } else if (time.sessionDuration >= 15) {
      score += 10 // 15ë¶„ ì´ìƒ ì§€ì†
    }

    // ë§ˆì§€ë§‰ íœ´ì‹ ì‹œê°„ ê¸°ë°˜ ì ìˆ˜
    if (time.lastBreakTime >= 60) {
      score += 15 // 1ì‹œê°„ ì´ìƒ íœ´ì‹ ì—†ìŒ
    } else if (time.lastBreakTime >= 30) {
      score += 10 // 30ë¶„ ì´ìƒ íœ´ì‹ ì—†ìŒ
    }

    // ì—°ì† ì§‘ì¤‘ ì‹œê°„ ê¸°ë°˜ ì ìˆ˜
    if (time.consecutiveFocusTime >= 45) {
      score += 15 // 45ë¶„ ì´ìƒ ì—°ì† ì§‘ì¤‘
    } else if (time.consecutiveFocusTime >= 25) {
      score += 10 // 25ë¶„ ì´ìƒ ì—°ì† ì§‘ì¤‘
    }

    return Math.max(0, Math.min(100, score))
  }

  /**
   * ì „ì²´ ì‹ ë¢°ë„ ê³„ì‚°
   */
  private static calculateConfidence(features: FocusFeatures): number {
    let confidence = 0.5
    let factorCount = 0

    if (features.visual) {
      confidence += 0.2
      factorCount++
    }
    if (features.audio) {
      confidence += 0.2
      factorCount++
    }
    if (features.behavior) {
      confidence += 0.15
      factorCount++
    }
    if (features.time) {
      confidence += 0.1
      factorCount++
    }

    // ë°ì´í„°ê°€ ë§ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ì¦ê°€
    if (factorCount > 0) {
      confidence += (factorCount - 1) * 0.05
    }

    return Math.min(1.0, confidence)
  }

  /**
   * ë¶„ì„ ê²°ê³¼ ìƒì„±
   */
  private static generateAnalysis(
    scores: FocusScoreResult['breakdown'], 
    features: FocusFeatures
  ): FocusScoreResult['analysis'] {
    const factors = [
      { name: 'ì‹œê°ì  ì§‘ì¤‘ë„', score: scores.visual, key: 'visual' },
      { name: 'ì²­ê°ì  ì§‘ì¤‘ë„', score: scores.audio, key: 'audio' },
      { name: 'í–‰ë™ íŒ¨í„´', score: scores.behavior, key: 'behavior' },
      { name: 'ì‹œê°„ ê´€ë¦¬', score: scores.time, key: 'time' }
    ]

    // ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
    factors.sort((a, b) => b.score - a.score)

    const primaryFactor = factors[0].name
    const secondaryFactor = factors[1].name

    // ê¶Œì¥ì‚¬í•­ ìƒì„±
    const recommendations: string[] = []
    
    if (scores.visual < 60) {
      recommendations.push('ìì„¸ë¥¼ ë°”ë¥´ê²Œ í•˜ê³  í™”ë©´ì„ ì •ë©´ìœ¼ë¡œ ì‘ì‹œí•˜ì„¸ìš”')
    }
    if (scores.audio < 60) {
      recommendations.push('í•™ìŠµê³¼ ê´€ë ¨ëœ ë‚´ìš©ìœ¼ë¡œ ëŒ€í™”ë¥¼ ìœ ì§€í•˜ì„¸ìš”')
    }
    if (scores.behavior < 60) {
      recommendations.push('ë¶ˆí•„ìš”í•œ íƒ­ ì „í™˜ì„ ì¤„ì´ê³  ì‘ì—…ì— ì§‘ì¤‘í•˜ì„¸ìš”')
    }
    if (scores.time < 60) {
      recommendations.push('ì ì ˆí•œ íœ´ì‹ê³¼ í•¨ê»˜ ì§€ì†ì ì¸ ì§‘ì¤‘ì„ ìœ ì§€í•˜ì„¸ìš”')
    }

    if (recommendations.length === 0) {
      recommendations.push('í˜„ì¬ ìƒíƒœê°€ ì–‘í˜¸í•©ë‹ˆë‹¤. ì´ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”!')
    }

    return {
      primaryFactor,
      secondaryFactor,
      recommendations
    }
  }

  /**
   * ë°œí™” ì‹œì  ì§‘ì¤‘ë„ ë³´ì •ì„ í¬í•¨í•œ ì‹¤ì‹œê°„ ì§‘ì¤‘ë„ ëª¨ë‹ˆí„°ë§
   */
  static trackFocusScoreWithSpeechCorrection(sessionId: string, features: FocusFeatures): Promise<FocusScoreResult & { correctionApplied?: boolean }> {
    return new Promise(async (resolve) => {
      try {
        // íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€ (ë³´ì • ë¡œì§ì„ ìœ„í•´)
        const featuresWithTimestamp = {
          ...features,
          timestamp: features.timestamp || Date.now()
        }
        
        // ì§‘ì¤‘ë„ ì ìˆ˜ ê³„ì‚° (ë³´ì • ë¡œì§ í¬í•¨)
        const result = this.calculateFocusScore(featuresWithTimestamp)
        
        // ë³´ì • ì ìš© ì—¬ë¶€ í™•ì¸
        const focusStatus = determineFocusStatus(featuresWithTimestamp)
        const correctionApplied = focusStatus.isCorrected || false
        
        // ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        const response = await fetch('/api/focus-score', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            sessionId,
            focusScore: result.score,
            timestamp: new Date().toISOString(),
            confidence: result.confidence,
            analysisMethod: correctionApplied ? 'speech_corrected_ai_engine' : 'ai_engine',
            features: featuresWithTimestamp,
            correctionApplied,
            correctionReason: focusStatus.correctionReason
          })
        })

        if (response.ok) {
          console.log('âœ… ì§‘ì¤‘ë„ ì ìˆ˜ ì €ì¥ ì„±ê³µ:', {
            score: result.score,
            correctionApplied,
            correctionReason: focusStatus.correctionReason
          })
        } else {
          console.warn('âš ï¸ ì§‘ì¤‘ë„ ì ìˆ˜ ì €ì¥ ì‹¤íŒ¨:', response.status)
        }

        resolve({
          ...result,
          correctionApplied
        })
      } catch (error) {
        console.error('âŒ ì§‘ì¤‘ë„ ì ìˆ˜ ì¶”ì  ì‹¤íŒ¨:', error)
        resolve({
          ...this.calculateFocusScore(features),
          correctionApplied: false
        })
      }
    })
  }

  /**
   * ì‹¤ì‹œê°„ ì§‘ì¤‘ë„ ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ ì ìˆ˜ ì¶”ì  (ê¸°ì¡´ ë²„ì „ - í•˜ìœ„ í˜¸í™˜ì„±)
   */
  static trackFocusScore(sessionId: string, features: FocusFeatures): Promise<FocusScoreResult> {
    return new Promise(async (resolve) => {
      try {
        // ì§‘ì¤‘ë„ ì ìˆ˜ ê³„ì‚°
        const result = this.calculateFocusScore(features)
        
        // ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        const response = await fetch('/api/focus-score', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify({
            sessionId,
            focusScore: result.score,
            timestamp: new Date().toISOString(),
            confidence: result.confidence,
            analysisMethod: 'ai_engine',
            features
          })
        })

        if (response.ok) {
          console.log('âœ… ì§‘ì¤‘ë„ ì ìˆ˜ ì €ì¥ ì„±ê³µ:', result.score)
        } else {
          console.warn('âš ï¸ ì§‘ì¤‘ë„ ì ìˆ˜ ì €ì¥ ì‹¤íŒ¨:', response.status)
        }

        resolve(result)
      } catch (error) {
        console.error('âŒ ì§‘ì¤‘ë„ ì ìˆ˜ ì¶”ì  ì‹¤íŒ¨:', error)
        resolve(this.calculateFocusScore(features)) // ê³„ì‚°ëœ ì ìˆ˜ë¼ë„ ë°˜í™˜
      }
    })
  }
}
