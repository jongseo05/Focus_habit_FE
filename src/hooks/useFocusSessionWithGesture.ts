import { useCallback, useEffect, useRef, useState } from 'react'
import { useWebSocket } from './useWebSocket'
import { useMediaStream } from './useMediaStream'
import { FrameStreamer } from '@/lib/websocket/utils'
import { useDashboardStore } from '@/stores/dashboardStore'
import { useFocusSessionActions } from '@/stores/focusSessionStore'
import type { WebcamFrameAnalysisResult, FocusAnalysisFeatures } from '@/types/websocket'
import { useFocusSessionErrorHandler } from '@/hooks/useFocusSessionErrorHandler'
import { FocusSessionErrorType, FocusSessionStatus } from '@/types/focusSession'
import { determineFocusStatus, type FocusStatus } from '@/lib/focusScoreEngine'
import { supabaseBrowser } from '@/lib/supabase/client'
import type { GestureFeatures } from '@/types/focusSession'

interface FocusSessionWithGestureOptions {
  frameRate?: number
  enableGestureRecognition?: boolean
  gestureJpegQuality?: number
}

interface FocusSessionWithGestureReturn {
  // MediaStream ê¸°ëŠ¥ ì „ì²´ë¥¼ í¬í•¨
  stream: MediaStream | null
  isLoading: boolean
  error: string | null
  isPermissionGranted: boolean
  isPermissionDenied: boolean
  requestPermission: () => Promise<boolean>
  startStream: () => Promise<boolean>
  stopStream: () => void
  resetError: () => void
  retryPermission: () => Promise<boolean>
  
  // ì œìŠ¤ì²˜ ì¸ì‹ ì¶”ê°€ ê¸°ëŠ¥
  isGestureRecognitionActive: boolean
  gestureWebSocketConnected: boolean
  gestureFramesSent: number
  
  // ì§‘ì¤‘ ì„¸ì…˜ ì—ëŸ¬ ì²˜ë¦¬
  sessionStatus: FocusSessionStatus
  sessionErrors: any[]
  lastSessionError: any | null
  canRecoverFromError: boolean
  retrySessionRecovery: () => Promise<boolean>
}

export function useFocusSessionWithGesture(
  isRunning: boolean,
  sessionId: string | null | undefined,
  options: FocusSessionWithGestureOptions = {}
) {
  
  const {
    frameRate = 10,
    enableGestureRecognition = true,
    gestureJpegQuality = 0.8
  } = options
  
  // ê¸°ì¡´ ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¼ í›… ì‚¬ìš©
  const mediaStream = useMediaStream()
  
  // ì œìŠ¤ì²˜ ì¸ì‹ ìƒíƒœ
  const [gestureFramesSent, setGestureFramesSent] = useState(0)
  const [isGestureActive, setIsGestureActive] = useState(false)

  // 1. ìƒíƒœ ì¶”ê°€
  const [isSpeechRecognitionActive, setIsSpeechRecognitionActive] = useState(false)

  // ì§‘ì¤‘ ì„¸ì…˜ í†µí•© ì—ëŸ¬ í•¸ë“¤ëŸ¬
  const { 
    state: errorHandlerState, 
    handleError, 
    classifyError, 
    retryRecovery,
    clearErrors 
  } = useFocusSessionErrorHandler({
    config: {
      autoRecovery: true,
      maxRecoveryAttempts: 3,
      gracefulDegradation: true,
      fallbackMode: true
    },
    onError: (error) => {
      
      // íŠ¹ì • ì—ëŸ¬ íƒ€ì…ì— ë”°ë¥¸ ì²˜ë¦¬
      switch (error.type) {
        case FocusSessionErrorType.CAMERA_DISCONNECTED:
          setIsGestureActive(false)
          break
        case FocusSessionErrorType.WEBSOCKET_FAILED:
        case FocusSessionErrorType.GESTURE_SERVER_ERROR:
          setIsGestureActive(false)
          break
      }
    },
    onRecoveryStart: (errorType) => {
    },
    onRecoverySuccess: (errorType) => {
      // ë³µêµ¬ ì„±ê³µ ì‹œ ì œìŠ¤ì²˜ ì¸ì‹ ì¬ì‹œì‘
      if (isRunning && mediaStream.stream && mediaStream.isPermissionGranted) {
        setTimeout(() => {
          startGestureRecognition()
        }, 1000)
      }
    },
    onRecoveryFailed: (error) => {
      setIsGestureActive(false)
    },
    onSessionInterrupted: () => {
      setIsGestureActive(false)
    },
    onFallbackMode: () => {
      // ì¹´ë©”ë¼ ì—†ì´ ê¸°ë³¸ ì§‘ì¤‘ ì„¸ì…˜ ìœ ì§€
    }
  })
  
    // í”„ë ˆì„ ìŠ¤íŠ¸ë¦¬ë¨¸ì™€ ìˆ¨ê²¨ì§„ ë¹„ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ì°¸ì¡°
  const frameStreamerRef = useRef<FrameStreamer | null>(null)
  const hiddenVideoRef = useRef<HTMLVideoElement | null>(null)
  
  // ì œìŠ¤ì²˜ í”¼ì³ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜
  const saveGestureFeatures = useCallback(async (features: GestureFeatures) => {
    let currentSessionId = sessionId
    
    // If sessionId is not provided, try to fetch active session directly
    if (!currentSessionId) {
      try {
        const supabase = supabaseBrowser()
        const { data: { user }, error: authError } = await supabase.auth.getUser()
        
        if (!authError && user) {
          const { data: activeSession, error: sessionError } = await supabase
            .from('focus_session')
            .select('session_id')
            .eq('user_id', user.id)
            .is('ended_at', null)
            .order('started_at', { ascending: false })
            .limit(1)
            .single()
          
          if (!sessionError && activeSession) {
            currentSessionId = activeSession.session_id
          }
        }
      } catch (error) {
        console.error('Failed to fetch active session:', error)
      }
    }
    
    if (!currentSessionId) {
      console.error('No session ID available')
      return
    }
    
    try {
      const supabase = supabaseBrowser()
      
      // ML í”¼ì³ ë°ì´í„° ì €ì¥ ì œê±° (í”¼ì³ ì €ì¥ ë¶ˆí•„ìš”)

      // 2. focus_sample í…Œì´ë¸”ì— ê¸°ë³¸ ì§‘ì¤‘ë„ ì ìˆ˜ë§Œ ì €ì¥
      const { error: sampleError } = await supabase
        .from('focus_sample')
        .insert({
          session_id: currentSessionId,
          ts: new Date().toISOString(),
          score: features.focusScore,
          score_conf: features.focusConfidence,
          topic_tag: 'webcam_analysis'
        })
      
      if (sampleError) {
        console.error('Focus sample save failed:', sampleError)
      }

      // 3. ì§‘ì¤‘ ìƒíƒœ ë³€í™”ë¥¼ focus_event í…Œì´ë¸”ì— ì €ì¥ (í”¼ì³ ì œê±°)
      const { error: eventError } = await supabase
        .from('focus_event')
        .insert({
          session_id: currentSessionId,
          ts: new Date().toISOString(),
          event_type: 'focus',
          payload: {
            focus_score: features.focusScore,
            focus_confidence: features.focusConfidence,
            analysis_method: 'webcam_analysis'
          }
        })
      
      if (eventError) {
        console.error('Focus event save failed:', eventError)
      }

    } catch (error) {
      console.error('Gesture features save error:', error)
    }
  }, [sessionId])

  // ìƒˆë¡œìš´ ì›¹ìº  í”„ë ˆì„ ë¶„ì„ ê²°ê³¼ ìƒíƒœ
  const [webcamAnalysisResult, setWebcamAnalysisResult] = useState<WebcamFrameAnalysisResult | null>(null)
  const [focusFeatures, setFocusFeatures] = useState<FocusAnalysisFeatures | null>(null)
  const [lastFocusScore, setLastFocusScore] = useState<number>(85)

  // lastFocusScore ì—…ë°ì´íŠ¸ ë¡œê¹…
  useEffect(() => {
    console.log('ğŸ“Š lastFocusScore ì—…ë°ì´íŠ¸:', lastFocusScore)
  }, [lastFocusScore])
  
  // ì œìŠ¤ì²˜ ì¸ì‹ ìƒíƒœ ì¶”ê°€
  const [currentGesture, setCurrentGesture] = useState<string>('neutral')
  const [lastGestureTime, setLastGestureTime] = useState<string>('')
  const [gestureHistory, setGestureHistory] = useState<Array<{ gesture: string; timestamp: string }>>([])
  
  // ì§‘ì¤‘ ì„¸ì…˜ ìŠ¤í† ì–´ì—ì„œ ì§‘ì¤‘ë„ ì—…ë°ì´íŠ¸ í•¨ìˆ˜ ê°€ì ¸ì˜¤ê¸°
  const { updateFocusScore } = useFocusSessionActions()

  // í—¤ë“œ í¬ì¦ˆë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì œìŠ¤ì²˜ íŒë‹¨í•˜ëŠ” í•¨ìˆ˜
  const determineGestureFromHeadPose = (headPose: { pitch: number; yaw: number; roll: number }): string => {
    const { pitch, yaw, roll } = headPose
    
    // ê³ ê°œ ìˆ™ì„ (pitchê°€ ì–‘ìˆ˜)
    if (pitch > 15) return 'head_down'
    // ê³ ê°œ ë“¤ê¸° (pitchê°€ ìŒìˆ˜)
    if (pitch < -15) return 'head_up'
    // ê³ ê°œ ì¢Œìš° íšŒì „ (yaw ì ˆëŒ“ê°’ì´ í¼)
    if (Math.abs(yaw) > 30) return 'head_turn'
    // ê³ ê°œ ê¸°ìš¸ê¸° (roll ì ˆëŒ“ê°’ì´ í¼)
    if (Math.abs(roll) > 20) return 'head_tilt'
    
    return 'neutral'
  }

  // ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ë””ë°”ìš´ì‹±ì„ ìœ„í•œ ref
  const saveTimeoutRef = useRef<NodeJS.Timeout | null>(null)
  const lastSavedScoreRef = useRef<number | null>(null)

  // ì§‘ì¤‘ë„ ì ìˆ˜ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜ (2ì´ˆ ë””ë°”ìš´ì‹±)
  const saveFocusScoreToDatabase = useCallback(async (
    sessionId: string, 
    focusScore: number, 
    confidence: number, 
    timestamp: number
  ) => {
    // ì´ì „ íƒ€ì´ë¨¸ê°€ ìˆìœ¼ë©´ ì·¨ì†Œ
    if (saveTimeoutRef.current) {
      clearTimeout(saveTimeoutRef.current)
    }

    // ë§ˆì§€ë§‰ ì €ì¥ëœ ì ìˆ˜ì™€ ê°™ìœ¼ë©´ ì €ì¥í•˜ì§€ ì•ŠìŒ (5ì  ì´ìƒ ì°¨ì´ë‚˜ë©´ ì €ì¥)
    if (lastSavedScoreRef.current !== null && Math.abs(lastSavedScoreRef.current - focusScore) < 5) {
      console.log('ğŸ“Š ì ìˆ˜ ë³€í™” ë¯¸ë¯¸, ì €ì¥ ê±´ë„ˆëœ€:', { last: lastSavedScoreRef.current, current: focusScore })
      return
    }

    // 1ì´ˆ í›„ì— ì €ì¥ (ë””ë°”ìš´ì‹± ì‹œê°„ ë‹¨ì¶•)
    saveTimeoutRef.current = setTimeout(async () => {
      try {
        const response = await fetch('/api/focus-score', {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
                      body: JSON.stringify({
              sessionId,
              focusScore,
              timestamp: new Date(timestamp).toISOString(),
              confidence,
              analysisMethod: 'webcam_analysis'
            })
        })

        if (response.ok) {
          lastSavedScoreRef.current = focusScore
        } else {
          console.warn('ì›¹ìº  ì§‘ì¤‘ë„ ì ìˆ˜ ì €ì¥ ì‹¤íŒ¨:', response.status)
        }
      } catch (error) {
        console.error('ì›¹ìº  ì§‘ì¤‘ë„ ì ìˆ˜ ì €ì¥ ì˜¤ë¥˜:', error)
      }
    }, 2000) // 2ì´ˆ ë””ë°”ìš´ì‹±
  }, [])

  // WebSocket ë©”ì‹œì§€ ì²˜ë¦¬ë¥¼ ìœ„í•œ ì§ì ‘ í•¸ë“¤ëŸ¬
  const handleWebSocketMessage = useCallback((rawData: any) => {
    console.log('ğŸ¯ handleWebSocketMessage í˜¸ì¶œë¨!', rawData)
    
    try {
      console.log('ğŸ“¨ WebSocket ë©”ì‹œì§€ ìˆ˜ì‹  ì‹œì‘:', {
        type: typeof rawData,
        isObject: typeof rawData === 'object',
        keys: rawData && typeof rawData === 'object' ? Object.keys(rawData) : 'N/A',
        timestamp: new Date().toISOString(),
        hasPredictionResult: rawData && typeof rawData === 'object' && 'prediction_result' in rawData
      })
      
      // rawDataê°€ ë¬¸ìì—´ì¸ ê²½ìš° JSON íŒŒì‹± ì‹œë„
      let parsedData = rawData
      if (typeof rawData === 'string') {
        try {
          parsedData = JSON.parse(rawData)
          console.log('ğŸ“¨ JSON íŒŒì‹± ì„±ê³µ:', parsedData)
        } catch (parseError) {
          console.log('ğŸ“¨ JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ ë°ì´í„°:', rawData)
          return
        }
      }
      
      console.log('ğŸ“¨ íŒŒì‹±ëœ ë°ì´í„°:', parsedData)
      console.log('ğŸ“¨ ì¡°ê±´ í™•ì¸:', {
        hasTimestamp: 'timestamp' in parsedData,
        hasPredictionResult: 'prediction_result' in parsedData,
        keys: Object.keys(parsedData)
      })
      
              // ìƒˆë¡œìš´ ì›¹ìº  í”„ë ˆì„ ë¶„ì„ ê²°ê³¼ ì²˜ë¦¬ (prediction_resultê°€ ìˆëŠ” ê²½ìš°)
        if (parsedData && typeof parsedData === 'object' && 'timestamp' in parsedData && 'prediction_result' in parsedData) {
          console.log('ğŸ¯ ì›¹ìº  ë¶„ì„ ê²°ê³¼:', parsedData)
          
          // ë¶„ì„ ê²°ê³¼ ì €ì¥
          setWebcamAnalysisResult(parsedData as WebcamFrameAnalysisResult)
          
          // ì§‘ì¤‘ë„ ì ìˆ˜ ì¶”ì¶œ ë° ë³€í™˜ (ì‹¤ì œ ì„œë²„
          const rawFocusScore = parsedData.prediction_result.prediction
          const confidence = parsedData.prediction_result.confidence
          
          // 0~1 ë²”ìœ„ë¥¼ 0~100 ë²”ìœ„ë¡œ ë³€í™˜
          const focusScore = Math.round(rawFocusScore * 100)
          
          console.log('ğŸ“Š ì§‘ì¤‘ë„ ì ìˆ˜ ì¶”ì¶œ:', {
            rawFocusScore,
            focusScore,
            confidence,
            timestamp: parsedData.timestamp
          })
          
          // ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
          const features: FocusAnalysisFeatures = {
            eyeStatus: {
              isOpen: parsedData.eye_status.status === 'OPEN',
              confidence: confidence,
              earValue: parsedData.eye_status.ear_value
            },
            headPose: {
              pitch: parsedData.head_pose.pitch,
              yaw: parsedData.head_pose.yaw,
              roll: parsedData.head_pose.roll
            },
            focusScore: {
              score: focusScore,
              confidence: confidence
            },
            timestamp: parsedData.timestamp
          }
          
          setFocusFeatures(features)
          console.log('ğŸ“Š setLastFocusScore í˜¸ì¶œ (prediction_result ìˆìŒ):', focusScore)
          setLastFocusScore(focusScore)
        
        // ì§‘ì¤‘ë„ ì ìˆ˜ ì—…ë°ì´íŠ¸ (ëŒ€ì‹œë³´ë“œ ìŠ¤í† ì–´)
        console.log('ğŸ”„ ëŒ€ì‹œë³´ë“œ ìŠ¤í† ì–´ ì—…ë°ì´íŠ¸ ì‹œë„:', focusScore)
        updateFocusScore(focusScore)
        
        // ì§‘ì¤‘ë„ ì ìˆ˜ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        if (sessionId && isRunning) {
          console.log('ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹œë„:', { sessionId, focusScore, confidence })
          saveFocusScoreToDatabase(sessionId, focusScore, confidence, parsedData.timestamp)
        }
        
        // ì œìŠ¤ì²˜ ì¸ì‹ ê²°ê³¼ë„ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        if (parsedData.head_pose) {
          const gestureData = {
            gesture: determineGestureFromHeadPose(parsedData.head_pose),
            timestamp: new Date(parsedData.timestamp).toISOString()
          }
          setCurrentGesture(gestureData.gesture)
          setLastGestureTime(gestureData.timestamp)
          setGestureHistory((prev: Array<{ gesture: string; timestamp: string }>) => [
            gestureData,
            ...prev.slice(0, 49)
          ])
        }
        
        return // ì •ìƒ ì²˜ë¦¬ ì™„ë£Œ
      }
              // ìƒˆë¡œìš´ ì„œë²„ ì‘ë‹µ êµ¬ì¡° ì²˜ë¦¬ (prediction_resultê°€ ì—†ëŠ” ê²½ìš°)
        else if (parsedData && typeof parsedData === 'object' && 'timestamp' in parsedData && 'eye_status' in parsedData && 'head_pose' in parsedData) {
          console.log('ğŸ¯ ìƒˆë¡œìš´ ì›¹ìº  ë¶„ì„ ê²°ê³¼ (prediction_result ì—†ìŒ):', parsedData)
          
          // ë¶„ì„ ê²°ê³¼ ì €ì¥
          setWebcamAnalysisResult(parsedData as WebcamFrameAnalysisResult)
          
          // ì§‘ì¤‘ë„ ì ìˆ˜ ê³„ì‚° (ê¸°ë³¸ê°’ ë˜ëŠ” ê³„ì‚° ë¡œì§)
          const confidence = 0.8 // ê¸°ë³¸ ì‹ ë¢°ë„
          const focusScore = 75 // ê¸°ë³¸ ì§‘ì¤‘ë„ ì ìˆ˜
          
          console.log('ğŸ“Š ê¸°ë³¸ ì§‘ì¤‘ë„ ì ìˆ˜ ì„¤ì •:', {
            focusScore,
            confidence,
            timestamp: parsedData.timestamp
          })
          
          // ê¸°ì¡´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
          const features: FocusAnalysisFeatures = {
            eyeStatus: {
              isOpen: parsedData.eye_status.status === 'OPEN',
              confidence: confidence,
              earValue: parsedData.eye_status.ear_value
            },
            headPose: {
              pitch: parsedData.head_pose.pitch,
              yaw: parsedData.head_pose.yaw,
              roll: parsedData.head_pose.roll
            },
            focusScore: {
              score: focusScore,
              confidence: confidence
            },
            timestamp: parsedData.timestamp
          }
          
          setFocusFeatures(features)
          console.log('ğŸ“Š setLastFocusScore í˜¸ì¶œ (prediction_result ì—†ìŒ):', focusScore)
          setLastFocusScore(focusScore)
        
        // ì§‘ì¤‘ë„ ì ìˆ˜ ì—…ë°ì´íŠ¸ (ëŒ€ì‹œë³´ë“œ ìŠ¤í† ì–´)
        console.log('ğŸ”„ ëŒ€ì‹œë³´ë“œ ìŠ¤í† ì–´ ì—…ë°ì´íŠ¸ ì‹œë„:', focusScore)
        updateFocusScore(focusScore)
        
        // ì§‘ì¤‘ë„ ì ìˆ˜ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        if (sessionId && isRunning) {
          console.log('ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì‹œë„:', { sessionId, focusScore, confidence })
          saveFocusScoreToDatabase(sessionId, focusScore, confidence, parsedData.timestamp)
        }
        
        // ì œìŠ¤ì²˜ ì¸ì‹ ê²°ê³¼ë„ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
        if (parsedData.head_pose) {
          const gestureData = {
            gesture: determineGestureFromHeadPose(parsedData.head_pose),
            timestamp: new Date(parsedData.timestamp).toISOString()
          }
          setCurrentGesture(gestureData.gesture)
          setLastGestureTime(gestureData.timestamp)
          setGestureHistory((prev: Array<{ gesture: string; timestamp: string }>) => [
            gestureData,
            ...prev.slice(0, 49)
          ])
        }
        
        return // ì •ìƒ ì²˜ë¦¬ ì™„ë£Œ
      }
      // ê¸°ì¡´ ì œìŠ¤ì²˜ ì¸ì‹ ì‘ë‹µ ì²˜ë¦¬ (í•˜ìœ„ í˜¸í™˜ì„±)
      else if (parsedData && typeof parsedData === 'object' && 'gesture' in parsedData && 'timestamp' in parsedData) {
        const gestureData = parsedData as { gesture: string; timestamp: string }
        setCurrentGesture(gestureData.gesture)
        setLastGestureTime(gestureData.timestamp)
        setGestureHistory((prev: Array<{ gesture: string; timestamp: string }>) => [
          gestureData,
          ...prev.slice(0, 49)
        ])
        
        return // ì •ìƒ ì²˜ë¦¬ ì™„ë£Œ
      }
      // ê¸°ì¡´ ì‘ë‹µ êµ¬ì¡° ì²˜ë¦¬ (í•˜ìœ„ í˜¸í™˜ì„±)
      else if (parsedData && typeof parsedData === 'object') {
        const data = parsedData as any
        
        // í˜„ì¬ ë°›ê³  ìˆëŠ” ì‘ë‹µ êµ¬ì¡° ë¶„ì„
        const analysis = {
          timestamp: data.timestamp || 'N/A',
          eyeStatus: data.eye_status?.status || 'N/A',
          eyeValue: data.eye_status?.ear_value || 'N/A',
          handAction: data.hand_action?.action || 'N/A',
          handConfidence: data.hand_action?.confidence || 'N/A',
          headPose: {
            pitch: data.head_pose?.pitch || 'N/A',
            roll: data.head_pose?.roll || 'N/A',
            yaw: data.head_pose?.yaw || 'N/A'
          }
        }
        
        // ì§‘ì¤‘ ìƒíƒœ ê³„ì‚°ì„ ìœ„í•œ í”¼ì³ ë°ì´í„° êµ¬ì„±
        const focusFeatures = {
          visual: {
            eyeStatus: data.eye_status?.status || 'OPEN',
            earValue: data.eye_status?.ear_value || 0.3,
            headPose: {
              pitch: data.head_pose?.pitch || 0,
              yaw: data.head_pose?.yaw || 0,
              roll: data.head_pose?.roll || 0
            },
            gazeDirection: 'FORWARD' as const
          },
          // ê¸°ë³¸ê°’ë“¤ (ì‹¤ì œë¡œëŠ” ë‹¤ë¥¸ ì„¼ì„œì—ì„œ ë°›ì•„ì™€ì•¼ í•¨)
          audio: {
            isSpeaking: false,
            speechContent: '',
            isStudyRelated: true,
            confidence: 0.8,
            audioLevel: 20
          },
          behavior: {
            mouseActivity: true,
            keyboardActivity: true,
            tabSwitches: 0,
            idleTime: 0
          },
          time: {
            sessionDuration: 0,
            lastBreakTime: 0,
            consecutiveFocusTime: 0
          }
        }
        
        // ì§‘ì¤‘ ìƒíƒœ ê³„ì‚°
        const focusStatusResult = determineFocusStatus(focusFeatures)
        
        console.log('ğŸ“Š ê¸°ì¡´ ì‘ë‹µ êµ¬ì¡° ì§‘ì¤‘ë„ ê³„ì‚°:', {
          focusStatus: focusStatusResult.status,
          focusConfidence: focusStatusResult.confidence,
          focusScore: focusStatusResult.score
        })
        
        // ì§‘ì¤‘ë„ ì ìˆ˜ ì—…ë°ì´íŠ¸ (ëŒ€ì‹œë³´ë“œ ìŠ¤í† ì–´)
        updateFocusScore(focusStatusResult.score)
        
        // ì œìŠ¤ì²˜ ì¸ì‹ ê²°ê³¼ë¥¼ DBì— ì €ì¥ (ì§‘ì¤‘ ìƒíƒœ í¬í•¨)
        if (data.timestamp) {
          const features = {
            frameNumber: gestureFramesSent,
            eyeStatus: data.eye_status?.status?.substring(0, 10), // 10ìë¡œ ì œí•œ
            earValue: data.eye_status?.ear_value,
            headPose: {
              pitch: data.head_pose?.pitch,
              roll: data.head_pose?.roll,
              yaw: data.head_pose?.yaw
            },
            focusStatus: focusStatusResult.status,
            focusConfidence: focusStatusResult.confidence,
            focusScore: focusStatusResult.score
          }
          
          saveGestureFeatures(features)
        } else {
          // ë°ì´í„° ì €ì¥ ì¡°ê±´ ë¯¸ì¶©ì¡±
        }
        
      }
    } catch (error) {
      // ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜ë¥¼ ì œìŠ¤ì²˜ ì„œë²„ ì˜¤ë¥˜ë¡œ ë¶„ë¥˜
      const gestureError = classifyError(error, 'gesture')
      handleError(gestureError)
    }
  }, [sessionId, isRunning, updateFocusScore, saveFocusScoreToDatabase, handleError, classifyError])

  // ì œìŠ¤ì²˜ ì¸ì‹ì„ ìœ„í•œ WebSocket - ì›¹ìº  ë¶„ì„ìš© URL ì‚¬ìš© (ì‚¬ìš©ì ID í¬í•¨)
  const { sendRawText, isConnected, connect, disconnect } = useWebSocket({
    url: 'wss://focushabit.site/ws/analysis'
  }, {
    onMessage: handleWebSocketMessage,
    onOpen: () => {
      console.log('ğŸ”— WebSocket ì—°ê²° ì„±ê³µ')
    },
    onClose: () => {
      console.log('ğŸ”Œ WebSocket ì—°ê²° ì¢…ë£Œ')
    },
    onError: (error) => {
      console.error('âŒ WebSocket ì˜¤ë¥˜:', error)
      // WebSocket ì˜¤ë¥˜ë¥¼ ì—ëŸ¬ í•¸ë“¤ëŸ¬ì— ì „ë‹¬
      const wsError = classifyError(error, 'websocket')
      handleError(wsError)
    }
  })
  
  // ì—°ê²° ìƒíƒœë¥¼ refë¡œ ì €ì¥í•˜ì—¬ í´ë¡œì € ë¬¸ì œ í•´ê²°
  const isConnectedRef = useRef(isConnected)
  isConnectedRef.current = isConnected

  // WebSocket ì—°ê²° ìƒíƒœ ë¡œê¹…
  useEffect(() => {
    console.log('ğŸ”— WebSocket ì—°ê²° ìƒíƒœ:', { 
      isConnected,
      sessionId,
      isRunning,
      enableGestureRecognition
    })
  }, [isConnected, sessionId, isRunning, enableGestureRecognition])
  
  // ì œìŠ¤ì²˜ ì¸ì‹ ì‹œì‘
  const startGestureRecognition = useCallback(() => {
    console.log('ğŸ¯ ì œìŠ¤ì²˜ ì¸ì‹ ì‹œì‘ ì‹œë„:', {
      hasStream: !!mediaStream.stream,
      enableGestureRecognition,
      isConnected,
      isGestureActive
    })
    
    if (!mediaStream.stream || !enableGestureRecognition) {
      console.log('âŒ ì œìŠ¤ì²˜ ì¸ì‹ ì‹œì‘ ì¡°ê±´ ë¯¸ì¶©ì¡±')
      return
    }
    
    // ì´ë¯¸ ì‹¤í–‰ ì¤‘ì´ë©´ ë¦¬í„´
    if (isGestureActive) {
      console.log('âŒ ì œìŠ¤ì²˜ ì¸ì‹ì´ ì´ë¯¸ í™œì„±í™”ë¨')
      return
    }
    
    // ê¸°ì¡´ í”„ë ˆì„ ìŠ¤íŠ¸ë¦¬ë¨¸ ì •ë¦¬
    if (frameStreamerRef.current) {
      frameStreamerRef.current.stop()
      frameStreamerRef.current = null
    }
    
    // ê¸°ì¡´ ë¹„ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ì •ë¦¬
    if (hiddenVideoRef.current) {
      hiddenVideoRef.current.srcObject = null
      hiddenVideoRef.current.remove()
      hiddenVideoRef.current = null
    }
    
    // ìˆ¨ê²¨ì§„ ë¹„ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ìƒì„±
    hiddenVideoRef.current = document.createElement('video')
    hiddenVideoRef.current.style.display = 'none'
    hiddenVideoRef.current.style.position = 'fixed'
    hiddenVideoRef.current.style.top = '-9999px'
    hiddenVideoRef.current.style.left = '-9999px'
    hiddenVideoRef.current.autoplay = true
    hiddenVideoRef.current.playsInline = true
    hiddenVideoRef.current.muted = true
    document.body.appendChild(hiddenVideoRef.current)
    
    // ìŠ¤íŠ¸ë¦¼ ì—°ê²°
    hiddenVideoRef.current.srcObject = mediaStream.stream
    
    // ë¹„ë””ì˜¤ ë¡œë“œ ì™„ë£Œ í›„ í”„ë ˆì„ ìŠ¤íŠ¸ë¦¬ë¨¸ ì‹œì‘
    const handleVideoReady = () => {
      console.log('ë¹„ë””ì˜¤ ë¡œë“œ ì™„ë£Œ, í”„ë ˆì„ ìŠ¤íŠ¸ë¦¬ë¨¸ ì‹œì‘')
      
      if (!hiddenVideoRef.current) return
      
      // ë¹„ë””ì˜¤ ì¬ìƒ ì‹œë„
      hiddenVideoRef.current.play().catch(error => {
        console.warn('ë¹„ë””ì˜¤ ìë™ ì¬ìƒ ì‹¤íŒ¨:', error)
      })
      
                    // í”„ë ˆì„ ìŠ¤íŠ¸ë¦¬ë¨¸ ìƒì„± ë° ì‹œì‘
        frameStreamerRef.current = new FrameStreamer(
          hiddenVideoRef.current,
          (base64) => {
            // ìµœì‹  ì—°ê²° ìƒíƒœ í™•ì¸
            const currentConnectionStatus = isConnectedRef.current
            
            console.log('ğŸ“¤ í”„ë ˆì„ ì „ì†¡ ì‹œë„:', { 
              isConnected: currentConnectionStatus, 
              base64Length: base64.length,
              frameCount: gestureFramesSent + 1
            })
            
            // WebSocketì´ ì—°ê²°ëœ ê²½ìš°ì—ë§Œ ì „ì†¡
            if (currentConnectionStatus) {
              sendRawText(base64)
              setGestureFramesSent((prev) => prev + 1)
            } else {
              console.warn('âš ï¸ WebSocket ì—°ê²°ë˜ì§€ ì•ŠìŒ, í”„ë ˆì„ ì „ì†¡ ê±´ë„ˆëœ€')
            }
          },
        (error) => {
          console.error('í”„ë ˆì„ ìŠ¤íŠ¸ë¦¬ë¨¸ ì˜¤ë¥˜:', error)
          setIsGestureActive(false)
          
          // ì„¸ì…˜ ì¢…ë£Œ ê³¼ì •ì—ì„œ ë°œìƒí•˜ëŠ” ìì—°ìŠ¤ëŸ¬ìš´ ì˜¤ë¥˜ëŠ” ë¬´ì‹œ
          if (!isRunning || error.message.includes('Video not ready')) {
            console.log('ì„¸ì…˜ ì¢…ë£Œ ì¤‘ ë°œìƒí•œ ìì—°ìŠ¤ëŸ¬ìš´ ì˜¤ë¥˜, ë¬´ì‹œí•¨:', error.message)
            return
          }
          
          // ì œìŠ¤ì²˜ ì„œë²„ ì˜¤ë¥˜ë¡œ ë¶„ë¥˜í•˜ì—¬ ì—ëŸ¬ í•¸ë“¤ëŸ¬ì— ì „ë‹¬
          const gestureError = classifyError(error, 'gesture')
          handleError(gestureError)
        },
        gestureJpegQuality
      )
      
      frameStreamerRef.current.setFrameRate(frameRate)
      frameStreamerRef.current.start()
      setIsGestureActive(true)
      setGestureFramesSent(0)
      console.log('ì œìŠ¤ì²˜ ì¸ì‹ ì‹œì‘ ì™„ë£Œ')
    }
    
    // ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì„¤ì •
    hiddenVideoRef.current.onloadedmetadata = handleVideoReady
    hiddenVideoRef.current.oncanplay = handleVideoReady
    
    hiddenVideoRef.current.onerror = (error) => {
      console.error('ë¹„ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ì˜¤ë¥˜:', error)
      setIsGestureActive(false)
      
      // ë¹„ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ì˜¤ë¥˜ë¥¼ ì¹´ë©”ë¼ ì˜¤ë¥˜ë¡œ ë¶„ë¥˜
      const cameraError = classifyError(error, 'camera')
      handleError(cameraError)
    }
     }, [
     mediaStream.stream, 
     enableGestureRecognition, 
     frameRate, 
     gestureJpegQuality,
     sendRawText,
     isGestureActive
   ])
  
  // ì œìŠ¤ì²˜ ì¸ì‹ ì¤‘ì§€
  const stopGestureRecognition = useCallback(() => {
    console.log('ì œìŠ¤ì²˜ ì¸ì‹ ì¤‘ì§€')
    
    // 1. ë¨¼ì € ìƒíƒœë¥¼ inactiveë¡œ ì„¤ì •í•˜ì—¬ ì¶”ê°€ í”„ë ˆì„ ì „ì†¡ ë°©ì§€
    setIsGestureActive(false)
    
    // 2. FrameStreamer ì¤‘ì§€ (ì—ëŸ¬ ì½œë°± ì œê±°í•˜ì—¬ cleanup ê³¼ì •ì—ì„œ ì˜¤ë¥˜ ë°©ì§€)
    if (frameStreamerRef.current) {
      frameStreamerRef.current.stop()
      frameStreamerRef.current = null
    }
    
    // 3. ë¹„ë””ì˜¤ ì—˜ë¦¬ë¨¼íŠ¸ ì •ë¦¬ (ì•½ê°„ì˜ ì§€ì—° í›„)
    if (hiddenVideoRef.current) {
      // ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ì œê±°
      hiddenVideoRef.current.onloadedmetadata = null
      hiddenVideoRef.current.oncanplay = null
      hiddenVideoRef.current.onerror = null
      
      // ë¹„ë””ì˜¤ ì¼ì‹œì •ì§€ í›„ ìŠ¤íŠ¸ë¦¼ í•´ì œ
      hiddenVideoRef.current.pause()
      hiddenVideoRef.current.srcObject = null
      
      // DOMì—ì„œ ì œê±°
      if (hiddenVideoRef.current.parentNode) {
        hiddenVideoRef.current.parentNode.removeChild(hiddenVideoRef.current)
      }
      hiddenVideoRef.current = null
    }
    
    setGestureFramesSent(0)
  }, [])
  
  // ì„¸ì…˜ ìƒíƒœì— ë”°ë¥¸ ìë™ ì œì–´
  useEffect(() => {
    console.log('ğŸ”„ ì„¸ì…˜ ìƒíƒœ ë³€í™”:', {
      isRunning,
      hasStream: !!mediaStream.stream,
      isPermissionGranted: mediaStream.isPermissionGranted,
      sessionId
    })
    
    if (isRunning && mediaStream.stream && mediaStream.isPermissionGranted) {
      console.log('ğŸ”— WebSocket ì—°ê²° ì‹œì‘')
      // WebSocket ì—°ê²° ì‹œì‘
      connect()
    } else {
      console.log('ğŸ›‘ ì œìŠ¤ì²˜ ì¸ì‹ ì¤‘ì§€')
      stopGestureRecognition()
      // ì„¸ì…˜ì´ ëë‚¬ìœ¼ë©´ WebSocket ì—°ê²° í•´ì œ
      if (!isRunning) {
        console.log('ğŸ”Œ ì„¸ì…˜ ì¢…ë£Œë¡œ ì¸í•œ WebSocket ì—°ê²° í•´ì œ')
        disconnect()
      }
    }
  }, [
    isRunning, 
    mediaStream.stream, 
    mediaStream.isPermissionGranted,
    sessionId
  ])

  // WebSocket ì—°ê²° ì™„ë£Œ ì‹œ ì œìŠ¤ì²˜ ì¸ì‹ ì‹œì‘ (ì•ˆì •í™”ëœ ì—°ê²°ë§Œ ì²˜ë¦¬)
  const [stableConnection, setStableConnection] = useState(false)
  const connectionStableTimerRef = useRef<NodeJS.Timeout | null>(null)
  
  useEffect(() => {
    console.log('ğŸ”— WebSocket ì—°ê²° ìƒíƒœ ë³€í™”:', {
      isRunning,
      hasStream: !!mediaStream.stream,
      isPermissionGranted: mediaStream.isPermissionGranted,
      enableGestureRecognition,
      isConnected,
      isGestureActive,
      stableConnection
    })
    
    // ì´ì „ íƒ€ì´ë¨¸ ì •ë¦¬
    if (connectionStableTimerRef.current) {
      clearTimeout(connectionStableTimerRef.current)
      connectionStableTimerRef.current = null
    }
    
    if (isConnected) {
      // ì—°ê²°ì´ ë˜ë©´ 3ì´ˆ í›„ì— ì•ˆì •í™”ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
      connectionStableTimerRef.current = setTimeout(() => {
        setStableConnection(true)
        console.log('âœ… WebSocket ì—°ê²° ì•ˆì •í™” ì™„ë£Œ')
      }, 3000)
    } else {
      setStableConnection(false)
      // ì—°ê²°ì´ ëŠì–´ì§€ë©´ ì œìŠ¤ì²˜ ì¸ì‹ë„ ì¤‘ì§€
      if (isGestureActive) {
        console.log('ğŸ”Œ WebSocket ì—°ê²° ëŠì–´ì§, ì œìŠ¤ì²˜ ì¸ì‹ ì¤‘ì§€')
        stopGestureRecognition()
      }
    }
    
    return () => {
      if (connectionStableTimerRef.current) {
        clearTimeout(connectionStableTimerRef.current)
        connectionStableTimerRef.current = null
      }
    }
  }, [isConnected])
  
  // ì•ˆì •í™”ëœ ì—°ê²°ì—ì„œ ì œìŠ¤ì²˜ ì¸ì‹ ì‹œì‘
  useEffect(() => {
    if (
      isRunning &&
      mediaStream.stream &&
      mediaStream.isPermissionGranted &&
      enableGestureRecognition &&
      stableConnection &&
      !isGestureActive
    ) {
      console.log('ğŸ¯ ì•ˆì •í™”ëœ WebSocket ì—°ê²°ì—ì„œ ì œìŠ¤ì²˜ ì¸ì‹ ì‹œì‘')
      const timer = setTimeout(() => {
        startGestureRecognition()
      }, 1000)
      
      return () => clearTimeout(timer)
    }
  }, [
    isRunning,
    mediaStream.stream,
    mediaStream.isPermissionGranted,
    enableGestureRecognition,
    stableConnection,
    isGestureActive
  ])
  
  // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
  useEffect(() => {
    return () => {
      console.log('ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸, ì •ë¦¬ ì‘ì—… ìˆ˜í–‰')
      stopGestureRecognition()
      disconnect()
      // ì €ì¥ íƒ€ì´ë¨¸ ì •ë¦¬
      if (saveTimeoutRef.current) {
        clearTimeout(saveTimeoutRef.current)
      }
      // ì—°ê²° ì•ˆì •í™” íƒ€ì´ë¨¸ ì •ë¦¬
      if (connectionStableTimerRef.current) {
        clearTimeout(connectionStableTimerRef.current)
      }
    }
  }, [stopGestureRecognition, disconnect]) // ì˜ì¡´ì„± ë°°ì—´ ì¶”ê°€
  
  // MediaStreamì˜ ëª¨ë“  ê¸°ëŠ¥ì„ ê·¸ëŒ€ë¡œ ë…¸ì¶œí•˜ë©´ì„œ ì œìŠ¤ì²˜ ê´€ë ¨ ê¸°ëŠ¥ ì¶”ê°€
  return {
    stream: mediaStream.stream,
    isLoading: mediaStream.isLoading,
    error: mediaStream.error,
    isPermissionGranted: mediaStream.isPermissionGranted,
    isPermissionDenied: mediaStream.isPermissionDenied,
    requestPermission: mediaStream.requestPermission,
    startStream: mediaStream.startStream,
    stopStream: mediaStream.stopStream,
    resetError: mediaStream.resetError,
    retryPermission: mediaStream.retryPermission,
    
    // ì œìŠ¤ì²˜ ì¸ì‹ ì¶”ê°€ ê¸°ëŠ¥
    isGestureRecognitionActive: isGestureActive,
    gestureWebSocketConnected: isConnected,
    gestureFramesSent,
    
    // ì§‘ì¤‘ ì„¸ì…˜ ì—ëŸ¬ ì²˜ë¦¬
    sessionStatus: errorHandlerState.status,
    sessionErrors: errorHandlerState.errors,
    lastSessionError: errorHandlerState.lastError,
    canRecoverFromError: errorHandlerState.lastError?.recoverable || false,
    retrySessionRecovery: retryRecovery,
    
    // ìƒˆë¡œìš´ ì›¹ìº  ë¶„ì„ ê²°ê³¼
    webcamAnalysisResult,
    focusFeatures,
    lastFocusScore,
  }
}

